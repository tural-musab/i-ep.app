name: Reality Check Automation

on:
  # Run when documentation files are updated
  push:
    branches: [ develop, main ]
    paths:
      - 'CLAUDE.md'
      - 'PROGRESS.md'
      - 'REALISTIC-TIMELINE-2025.md'
      - 'FOUNDATION-FIRST-STRATEGY.md'
      - 'ACTION-PLAN-OPTIMIZATION*.md'
  
  # Schedule daily reality checks
  schedule:
    - cron: '0 6 * * *'  # 6 AM daily
  
  # Manual trigger
  workflow_dispatch:
    inputs:
      check_type:
        description: 'Type of reality check'
        required: true
        default: 'full'
        type: choice
        options:
        - full
        - documentation-only
        - implementation-only

env:
  NODE_VERSION: '20'

jobs:
  reality-check:
    runs-on: ubuntu-latest
    name: Documentation vs Reality Verification
    timeout-minutes: 20
    
    permissions:
      contents: write
      issues: write
    
    outputs:
      reality_gap_detected: ${{ steps.gap_analysis.outputs.gap_detected }}
      gap_severity: ${{ steps.gap_analysis.outputs.severity }}
      action_required: ${{ steps.gap_analysis.outputs.action_required }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci --only=production
          npm install js-yaml axios cheerio --save-dev

      - name: Create verification workspace
        run: |
          mkdir -p reality-check/{claims,evidence,reports}
          echo "🔍 Reality Check Workspace Created"

      - name: Extract Documentation Claims
        id: extract_claims
        run: |
          echo "📋 Extracting claims from documentation..."
          
          # Extract percentage claims from CLAUDE.md
          grep -o "[0-9]\{1,3\}%" CLAUDE.md > reality-check/claims/percentages.txt || echo "No percentages found"
          
          # Extract status claims (completed, working, etc.)
          grep -o "✅ [^-]*" CLAUDE.md > reality-check/claims/completed-items.txt || echo "No completed items found"
          grep -o "🔴 [^-]*" CLAUDE.md > reality-check/claims/failed-items.txt || echo "No failed items found"
          
          # Extract API success claims
          grep -o "API.*[0-9]\{1,3\}%" CLAUDE.md > reality-check/claims/api-claims.txt || echo "No API claims found"
          
          # Count claims
          PERCENTAGE_CLAIMS=$(wc -l < reality-check/claims/percentages.txt)
          COMPLETED_CLAIMS=$(wc -l < reality-check/claims/completed-items.txt)
          API_CLAIMS=$(wc -l < reality-check/claims/api-claims.txt)
          
          echo "claims_found=true" >> $GITHUB_OUTPUT
          echo "percentage_claims=$PERCENTAGE_CLAIMS" >> $GITHUB_OUTPUT
          echo "completed_claims=$COMPLETED_CLAIMS" >> $GITHUB_OUTPUT
          echo "api_claims=$API_CLAIMS" >> $GITHUB_OUTPUT
          
          echo "📊 Claims extracted: $PERCENTAGE_CLAIMS percentages, $COMPLETED_CLAIMS completed items, $API_CLAIMS API claims"

      - name: Collect Real System Evidence
        id: collect_evidence
        run: |
          echo "🔍 Collecting real system evidence..."
          
          # Run our professional evidence collector
          if [ -f "scripts/evidence-collection-automation.js" ]; then
            echo "✅ Running professional evidence collector..."
            node scripts/evidence-collection-automation.js > reality-check/evidence/collection-log.txt 2>&1 || true
            
            # Check if evidence was collected
            if [ -d "verification/reports" ] && [ "$(ls -A verification/reports)" ]; then
              echo "evidence_collected=true" >> $GITHUB_OUTPUT
              echo "✅ Evidence collection completed"
              
              # Get latest evidence report
              LATEST_REPORT=$(ls -t verification/reports/evidence-collection-*.json | head -1)
              if [ -f "$LATEST_REPORT" ]; then
                cp "$LATEST_REPORT" reality-check/evidence/latest-evidence.json
                echo "evidence_file=$LATEST_REPORT" >> $GITHUB_OUTPUT
              fi
            else
              echo "evidence_collected=false" >> $GITHUB_OUTPUT
              echo "⚠️ Evidence collection failed or no reports generated"
            fi
          else
            echo "evidence_collected=false" >> $GITHUB_OUTPUT
            echo "❌ Evidence collection script not found"
          fi

      - name: Run Professional API Testing
        id: api_testing
        run: |
          echo "🧪 Running professional API tests..."
          
          # Run our professional API testing
          if [ -f "scripts/test-api-endpoints-professional.js" ]; then
            echo "✅ Running professional API tests..."
            timeout 300 node scripts/test-api-endpoints-professional.js > reality-check/evidence/api-test-log.txt 2>&1 || true
            
            # Check for API test results
            if [ -f "AUTHENTICATION_TEST_RESULTS_PROFESSIONAL.json" ]; then
              cp AUTHENTICATION_TEST_RESULTS_PROFESSIONAL.json reality-check/evidence/
              
              # Extract real API success rate
              REAL_API_RATE=$(node -e "
                try {
                  const data = JSON.parse(require('fs').readFileSync('AUTHENTICATION_TEST_RESULTS_PROFESSIONAL.json', 'utf8'));
                  const rate = Math.round((data.results.passed / data.results.total) * 100);
                  console.log(rate);
                } catch (e) {
                  console.log(0);
                }
              ")
              
              echo "api_tested=true" >> $GITHUB_OUTPUT
              echo "real_api_rate=$REAL_API_RATE" >> $GITHUB_OUTPUT
              echo "📊 Real API success rate: $REAL_API_RATE%"
            else
              echo "api_tested=false" >> $GITHUB_OUTPUT
              echo "real_api_rate=0" >> $GITHUB_OUTPUT
              echo "❌ API test results not found"
            fi
          else
            echo "api_tested=false" >> $GITHUB_OUTPUT
            echo "real_api_rate=0" >> $GITHUB_OUTPUT
            echo "❌ Professional API testing script not found"
          fi

      - name: Analyze Documentation vs Reality Gap
        id: gap_analysis
        run: |
          echo "🔍 Analyzing documentation vs reality gap..."
          
          # Create gap analysis script
          cat > reality-check/analyze-gap.js << 'EOF'
          const fs = require('fs');
          
          class RealityGapAnalyzer {
            constructor() {
              this.gaps = [];
              this.severity = 'low';
            }
            
            analyzeAPIGaps() {
              // Compare claimed vs real API success rates
              const claimsFile = 'reality-check/claims/api-claims.txt';
              const realAPIRate = process.env.REAL_API_RATE || '0';
              
              if (fs.existsSync(claimsFile)) {
                const claims = fs.readFileSync(claimsFile, 'utf8');
                
                // Look for API success rate claims
                const apiClaimMatch = claims.match(/(\d+\.?\d*)%/);
                if (apiClaimMatch) {
                  const claimedRate = parseFloat(apiClaimMatch[1]);
                  const actualRate = parseFloat(realAPIRate);
                  const gap = claimedRate - actualRate;
                  
                  if (gap > 10) {
                    this.gaps.push({
                      type: 'api_success_rate',
                      claimed: claimedRate,
                      actual: actualRate,
                      gap: gap,
                      severity: gap > 20 ? 'critical' : 'high'
                    });
                    
                    if (gap > 20) this.severity = 'critical';
                    else if (this.severity !== 'critical') this.severity = 'high';
                  }
                }
              }
            }
            
            analyzeCompletionGaps() {
              // Compare claimed completions vs evidence
              const completedFile = 'reality-check/claims/completed-items.txt';
              const evidenceFile = 'reality-check/evidence/latest-evidence.json';
              
              if (fs.existsSync(completedFile) && fs.existsSync(evidenceFile)) {
                try {
                  const completed = fs.readFileSync(completedFile, 'utf8').split('\n').filter(l => l.trim());
                  const evidence = JSON.parse(fs.readFileSync(evidenceFile, 'utf8'));
                  
                  // Check if verification score supports completion claims
                  const verificationScore = evidence.summary?.verificationScore || 0;
                  const completionClaims = completed.length;
                  
                  if (completionClaims > 5 && verificationScore < 70) {
                    this.gaps.push({
                      type: 'completion_claims',
                      claimed_completions: completionClaims,
                      verification_score: verificationScore,
                      gap: completionClaims - Math.floor(verificationScore / 10),
                      severity: 'high'
                    });
                    
                    if (this.severity !== 'critical') this.severity = 'high';
                  }
                } catch (error) {
                  console.log('Could not analyze completion gaps:', error.message);
                }
              }
            }
            
            analyzeBuildGaps() {
              // Check build claims vs evidence
              const evidenceFile = 'reality-check/evidence/latest-evidence.json';
              
              if (fs.existsSync(evidenceFile)) {
                try {
                  const evidence = JSON.parse(fs.readFileSync(evidenceFile, 'utf8'));
                  const buildEvidence = evidence.evidence?.build;
                  
                  if (buildEvidence && buildEvidence.buildStatus === 'failed') {
                    this.gaps.push({
                      type: 'build_status',
                      claimed: 'working',
                      actual: 'failed',
                      severity: 'critical'
                    });
                    
                    this.severity = 'critical';
                  }
                } catch (error) {
                  console.log('Could not analyze build gaps:', error.message);
                }
              }
            }
            
            generateReport() {
              this.analyzeAPIGaps();
              this.analyzeCompletionGaps();
              this.analyzeBuildGaps();
              
              const report = {
                timestamp: new Date().toISOString(),
                gaps_detected: this.gaps.length > 0,
                gap_count: this.gaps.length,
                severity: this.severity,
                action_required: this.gaps.length > 0,
                gaps: this.gaps,
                recommendations: this.generateRecommendations()
              };
              
              fs.writeFileSync('reality-check/reports/gap-analysis.json', JSON.stringify(report, null, 2));
              
              // Output for GitHub Actions
              console.log(`gap_count=${report.gap_count}`);
              console.log(`severity=${report.severity}`);
              console.log(`action_required=${report.action_required}`);
              
              return report;
            }
            
            generateRecommendations() {
              const recommendations = [];
              
              this.gaps.forEach(gap => {
                switch (gap.type) {
                  case 'api_success_rate':
                    recommendations.push('Update documentation with real API success rate, fix failing endpoints');
                    break;
                  case 'completion_claims':
                    recommendations.push('Reduce completion claims or improve implementation evidence');
                    break;
                  case 'build_status':
                    recommendations.push('Fix build errors before claiming system is working');
                    break;
                }
              });
              
              return recommendations;
            }
          }
          
          const analyzer = new RealityGapAnalyzer();
          const report = analyzer.generateReport();
          
          console.log('📊 Reality Gap Analysis Complete');
          console.log(`Gaps found: ${report.gap_count}`);
          console.log(`Severity: ${report.severity}`);
          EOF
          
          # Set environment variable for the script
          export REAL_API_RATE="${{ steps.api_testing.outputs.real_api_rate }}"
          
          # Run gap analysis
          node reality-check/analyze-gap.js > reality-check/reports/analysis-output.txt
          
          # Read outputs from the analysis
          if [ -f "reality-check/reports/gap-analysis.json" ]; then
            GAP_COUNT=$(node -e "console.log(JSON.parse(require('fs').readFileSync('reality-check/reports/gap-analysis.json', 'utf8')).gap_count)")
            SEVERITY=$(node -e "console.log(JSON.parse(require('fs').readFileSync('reality-check/reports/gap-analysis.json', 'utf8')).severity)")
            ACTION_REQUIRED=$(node -e "console.log(JSON.parse(require('fs').readFileSync('reality-check/reports/gap-analysis.json', 'utf8')).action_required)")
            
            echo "gap_detected=$([ $GAP_COUNT -gt 0 ] && echo 'true' || echo 'false')" >> $GITHUB_OUTPUT
            echo "gap_count=$GAP_COUNT" >> $GITHUB_OUTPUT
            echo "severity=$SEVERITY" >> $GITHUB_OUTPUT
            echo "action_required=$ACTION_REQUIRED" >> $GITHUB_OUTPUT
            
            echo "📊 Gap analysis complete: $GAP_COUNT gaps found (severity: $SEVERITY)"
          else
            echo "gap_detected=false" >> $GITHUB_OUTPUT
            echo "gap_count=0" >> $GITHUB_OUTPUT
            echo "severity=low" >> $GITHUB_OUTPUT
            echo "action_required=false" >> $GITHUB_OUTPUT
            echo "⚠️ Gap analysis failed"
          fi

      - name: Create Issue for Critical Gaps
        if: steps.gap_analysis.outputs.severity == 'critical' && steps.gap_analysis.outputs.action_required == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = 'reality-check/reports/gap-analysis.json';
            
            if (fs.existsSync(path)) {
              const report = JSON.parse(fs.readFileSync(path, 'utf8'));
              
              const issueBody = `
            # 🚨 Critical Documentation vs Reality Gap Detected
            
            **Detection Date**: ${report.timestamp}
            **Severity**: ${report.severity.toUpperCase()}
            **Gaps Found**: ${report.gap_count}
            
            ## 📊 Gap Analysis Results
            
            ${report.gaps.map(gap => `
            - **${gap.type}**: Claimed ${gap.claimed || gap.claimed_completions || 'working'}, Actual ${gap.actual || gap.verification_score || 'failed'} (Gap: ${gap.gap || 'N/A'})
            `).join('')}
            
            ## 💡 Recommendations
            
            ${report.recommendations.map(rec => `- ${rec}`).join('\n')}
            
            ## 🔧 Required Actions
            
            1. Review and correct documentation claims
            2. Fix identified implementation issues
            3. Re-run professional verification
            4. Update progress assessments with evidence-based data
            
            ---
            
            **Generated by**: Reality Check Automation Pipeline
            **Workflow Run**: ${{ github.run_id }}
            `;
              
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: `🚨 Critical Reality Gap: ${report.gap_count} Documentation vs Implementation Discrepancies`,
                body: issueBody,
                labels: ['documentation', 'critical', 'reality-check']
              });
            }

      - name: Upload Reality Check Reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: reality-check-reports-${{ github.run_number }}
          path: |
            reality-check/
            verification/
          retention-days: 30

      - name: Summary
        if: always()
        run: |
          echo "## 🔍 Reality Check Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ steps.gap_analysis.outputs.gap_detected }}" = "true" ]; then
            echo "🚨 **Documentation vs Reality Gap Detected**" >> $GITHUB_STEP_SUMMARY
            echo "- **Gaps Found**: ${{ steps.gap_analysis.outputs.gap_count }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Severity**: ${{ steps.gap_analysis.outputs.severity }}" >> $GITHUB_STEP_SUMMARY
            echo "- **Action Required**: ${{ steps.gap_analysis.outputs.action_required }}" >> $GITHUB_STEP_SUMMARY
            
            if [ "${{ steps.gap_analysis.outputs.severity }}" = "critical" ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "⚠️ **Critical action required**: Documentation claims significantly exceed implementation evidence" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "✅ **No Significant Reality Gap Detected**" >> $GITHUB_STEP_SUMMARY
            echo "Documentation appears to align with implementation evidence" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 📊 Verification Details" >> $GITHUB_STEP_SUMMARY
          echo "- **Claims Analyzed**: ${{ steps.extract_claims.outputs.percentage_claims }} percentages, ${{ steps.extract_claims.outputs.completed_claims }} completions" >> $GITHUB_STEP_SUMMARY
          echo "- **Evidence Collected**: ${{ steps.collect_evidence.outputs.evidence_collected }}" >> $GITHUB_STEP_SUMMARY
          echo "- **API Testing**: ${{ steps.api_testing.outputs.api_tested }} (Rate: ${{ steps.api_testing.outputs.real_api_rate }}%)" >> $GITHUB_STEP_SUMMARY